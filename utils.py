# utils.py
import streamlit as st
import pandas as pd
import re
from datetime import datetime
from streamlit_gsheets import GSheetsConnection
import config as cfg  # config.py ì„í¬íŠ¸

def load_data():
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        # worksheet ì¸ì ì¶”ê°€ (ê¸°ë³¸ê°’: ì²«ë²ˆì§¸ ì‹œíŠ¸)
        df = conn.read(spreadsheet=cfg.SHEET_URL, worksheet=cfg.WORKSHEET_NAME_LIST, ttl=0)
        
        if df.empty or len(df.columns) < len(cfg.COLUMNS): 
            return pd.DataFrame(columns=cfg.COLUMNS)
        
        missing_cols = set(cfg.COLUMNS) - set(df.columns)
        for c in missing_cols: df[c] = ""
        
        df = df[cfg.COLUMNS].fillna("")
        df['í‰ì '] = pd.to_numeric(df['í‰ì '], errors='coerce').fillna(0.0)
        df = df.astype({c: str for c in df.columns if c != 'í‰ì '})
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=cfg.COLUMNS)

def save_data(df):
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        conn.update(spreadsheet=cfg.SHEET_URL, data=df)
    except Exception as e:
        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

def extract_url(text):
    if not isinstance(text, str): return ""
    match = re.search(r'(https?://\S+)', text)
    if match: return match.group(1)
    return text

def get_unique_values(df, column, defaults=[]):
    if column in df.columns:
        existing = set()
        for item in df[column].unique():
            if item:
                existing.update([x.strip() for x in str(item).split(',')])
        return sorted(list(existing.union(defaults)))
    return sorted(defaults)

def aggregate_reviews(df):
    if df.empty: return df
    grouped = df.groupby('ì‹ë‹¹ëª…').agg({
        'ì¹´í…Œê³ ë¦¬': 'first', 'ë©”ë‰´í‚¤ì›Œë“œ': 'first', 'ë¶„ìœ„ê¸°í‚¤ì›Œë“œ': 'first',
        'ê°€ê²©ëŒ€': 'first', 'ê±°ë¦¬': 'first', 'ìµœëŒ€ìˆ˜ìš©ì¸ì›': 'first',
        'ì „í™”ë²ˆí˜¸': 'first', 'ë„¤ì´ë²„ì§€ë„URL': 'first', 'íœ´ë¬´ì¼': 'first',
        'í‰ì ': 'mean', 'í•œì¤„í‰': lambda x: list(x), 'ì‘ì„±ì': lambda x: list(x)
    }).reset_index()
    grouped['í‰ì '] = grouped['í‰ì '].round(1)
    return grouped

# [ì‹ ê·œ] ì‹ì‚¬ ê¸°ë¡ ë¡œë“œ
def load_history():
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        df = conn.read(spreadsheet=cfg.SHEET_URL, worksheet=cfg.WORKSHEET_NAME_HISTORY, ttl=0)
        
        if df.empty: return pd.DataFrame(columns=cfg.COLUMNS_HISTORY)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì¥
        missing_cols = set(cfg.COLUMNS_HISTORY) - set(df.columns)
        for c in missing_cols: df[c] = ""
        return df[cfg.COLUMNS_HISTORY].fillna("")
    except Exception:
        st.error(f"íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}") 
        return pd.DataFrame(columns=cfg.COLUMNS_HISTORY)
# 2. ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (ê¸°ì¡´ í•¨ìˆ˜ ìˆ˜ì •)
def save_data(df):
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        conn.update(spreadsheet=cfg.SHEET_URL, worksheet=cfg.WORKSHEET_NAME_LIST, data=df)
    except Exception as e:
        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

def add_history_row(new_row_dict):
    # 1. ì–´ë””ì— ì“¸ ê±´ì§€ ì£¼ì†Œë¶€í„° ì¶œë ¥ (í„°ë¯¸ë„ í™•ì¸ìš©)
    print("\n---------------------------------------------------")
    print(f"ğŸ”¥ [DEBUG] ì“°ê¸° ì‹œë„ ì¤‘...")
    print(f"ğŸ¯ íƒ€ê²Ÿ ì‹œíŠ¸ URL: {cfg.SHEET_URL}")
    print(f"ğŸ¯ íƒ€ê²Ÿ íƒ­ ì´ë¦„: {cfg.WORKSHEET_NAME_HISTORY}")

    # 2. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    df = load_history()
    print(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜: {len(df)}ê°œ")

    # 3. ë°ì´í„° í•©ì¹˜ê¸°
    new_df = pd.DataFrame([new_row_dict])
    updated_df = pd.concat([df, new_df], ignore_index=True)
    
    # [ì¤‘ìš”] ë°ì´í„° íƒ€ì… ê°•ì œ ë³€í™˜ (ìˆ«ì/ë‚ ì§œ ê¹¨ì§ ë°©ì§€)
    updated_df = updated_df.astype(str)
    
    print(f"ğŸ“ ì €ì¥í•  ë°ì´í„° ê°œìˆ˜: {len(updated_df)}ê°œ")
    print(f"ğŸ’¾ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n{updated_df.tail(1)}")

    # 4. ê°•ì œ ì“°ê¸° ë° ìºì‹œ ì‚­ì œ
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        
        # ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        conn.update(
            spreadsheet=cfg.SHEET_URL, 
            worksheet=cfg.WORKSHEET_NAME_HISTORY, 
            data=updated_df
        )
        
        # ìºì‹œ ë‚ ë¦¬ê¸° (ë§¤ìš° ì¤‘ìš”)
        st.cache_data.clear()
        print("âœ… [SUCCESS] ì—…ë°ì´íŠ¸ ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ (ì—ëŸ¬ ì—†ìŒ)")
        print("---------------------------------------------------\n")
        return True

    except Exception as e:
        print(f"âŒ [FAIL] ì €ì¥ ì¤‘ ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")
        st.error(f"ì €ì¥ ì‹œìŠ¤í…œ ì—ëŸ¬: {e}")
        return False
    
